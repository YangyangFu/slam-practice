{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Detection and Description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 as cv \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Harris Corner Detection\n",
    "\n",
    "**Goal**\n",
    "- Harris Corner Detection algorithm\n",
    "- cv2.cornerHarris(), cv2.cornerSubPix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory\n",
    "\n",
    "Corners are regions in the image with large variation in intensity in all the directions.\n",
    "One early attempt to find these corners was done by Chris Harris & Mike Stephens in their paper A Combined Corner and Edge Detector in 1988.\n",
    "\n",
    "The algorithm procedure is as follows:\n",
    "- 1. Determine which windows produce very large variations in intensity when moved in both X and Y directions.\n",
    "- 2. With each such window found, a score R is computed.\n",
    "- 3. After applying a threshold to this score, important corners are selected & marked.\n",
    "\n",
    "Find the difference in intensity for a displacement of $(u,v)$ in all directions.\n",
    "\n",
    "$$\n",
    "E(u,v) = \\sum_{x,y} w(x,y)[I(x+u,y+v) - I(x,y)]^2\n",
    "$$\n",
    "\n",
    "where $I(x,y)$ is the intensity of the image at pixel $(x,y)$ and $w(x,y)$ is a window function. The window is either a rectangular window or a Gaussian window which gives weights to pixels underneath.\n",
    "\n",
    "We have to maximize this function $E(u,v)$ for corner detection. That means, we have to maximize the second term. Applying Taylor Expansion to the second term, we get the score function.\n",
    "\n",
    "The final equation after derivation is:\n",
    "$$\n",
    "E(u,v) \\approx \\begin{bmatrix} u & v \\end{bmatrix} M \\begin{bmatrix} u \\\\ v \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $M$ is a matrix of derivatives called **structure tensor** given by:\n",
    "\n",
    "$$\n",
    "M = \\sum_{x,y} w(x,y) \\begin{bmatrix} I_x I_x & I_x I_y \\\\ I_x I_y & I_y I_y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $I_x$ and $I_y$ are image derivatives in $x$ and $y$ directions respectively.\n",
    "\n",
    "Then, the score function is:\n",
    "\n",
    "$$\n",
    "R = det(M) - k(trace(M))^2\n",
    "$$\n",
    "\n",
    "where $det(M) = \\lambda_1 \\lambda_2$ and $trace(M) = \\lambda_1 + \\lambda_2$. $\\lambda_1$ and $\\lambda_2$ are the eigenvalues of $M$.\n",
    "\n",
    "So, the values of $\\lambda_1$ and $\\lambda_2$ decide whether a region is corner, edge or flat.\n",
    "- when $|R|$ is small, which happens when $\\lambda_1$ and $\\lambda_2$ are small, the region is flat.\n",
    "- when $R<0$, which happens when $\\lambda_1 >> \\lambda_2$ or vice versa, the region is edge.\n",
    "- when $R$ is large, which happens when $\\lambda_1$ and $\\lambda_2$ are large and $\\lambda_1 \\sim \\lambda_2$, the region is a corner.\n",
    "\n",
    "The result of Harris Corner Detection is a grayscale image with these scores. Thresholding for a suitable value gives the corner points.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV Implementation\n",
    "\n",
    "OpenCV has the function `cv2.cornerHarris()` for this purpose. Its arguments are:\n",
    "- img - Input image, it should be grayscale and float32 type.\n",
    "- blockSize - It is the size of neighbourhood considered for corner detection\n",
    "- ksize - Aperture parameter of Sobel derivative used.\n",
    "- k - Harris detector free parameter in the equation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'messi5.jpg'\n",
    "img = cv.imread(filename)\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "img_gray = np.float32(img_gray)\n",
    "dst = cv.cornerHarris(img_gray, 2, 3, 0.04)\n",
    "\n",
    "# result is dilated for marking the corners, not important\n",
    "dst = cv.dilate(dst, None)\n",
    "\n",
    "# threshold for an optimal value, it may vary depending on the image\n",
    "img[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "\n",
    "cv.imshow('dst', img)\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want to find the corners with maximum accuracy. OpenCV comes with a function `cv2.cornerSubPix()` which further refines the corners detected with sub-pixel accuracy. Below is an example. As usual, we need to find the harris corners first. Then we pass the centroids of these corners (There may be a bunch of pixels at a corner, we take their centroid) to refine them. Harris corners are marked in red pixels and refined corners are marked in green pixels. For this function, we have to define the criteria when to stop the iteration. We stop it after a specified number of iteration or a certain accuracy is achieved, whichever occurs first. We also need to define the size of neighbourhood it would search for corners.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'messi5.jpg'\n",
    "img = cv.imread(filename)\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "img_gray = np.float32(img_gray)\n",
    "dst = cv.cornerHarris(img_gray, 2, 3, 0.04)\n",
    "\n",
    "# result is dilated for marking the corners, not important\n",
    "dst = cv.dilate(dst, None)\n",
    "ret, dst = cv.threshold(dst, 0.01 * dst.max(), 255, 0)\n",
    "dst = np.uint8(dst)\n",
    "\n",
    "# find centroids\n",
    "ret, labels, stats, centroids = cv.connectedComponentsWithStats(dst)\n",
    "\n",
    "# define the criteria to stop and refine the corners\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "corners = cv.cornerSubPix(img_gray, np.float32(centroids), (5, 5), (-1, -1), criteria)\n",
    "\n",
    "# now draw them\n",
    "res = np.hstack((centroids,corners))\n",
    "res = np.int0(res)\n",
    "img[res[:,1],res[:,0]]=[0,0,255]\n",
    "img[res[:,3],res[:,2]] = [0,255,0]\n",
    "\n",
    "cv.imwrite('subpixel_messi5.jpg', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
